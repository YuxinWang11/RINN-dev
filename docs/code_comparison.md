# R-INN ä»£ç å¯¹æ¯”æŠ¥å‘Š

**ç”Ÿæˆæ—¥æœŸ**: 2026-02-14  
**å¯¹æ¯”ä»“åº“**:
- **ä»“åº“1ï¼ˆä½ ä»¬çš„ä»£ç ï¼‰**: `/Users/tianzhuohang/Desktop/ç§‘ç ”/R_INN_opencode/`
- **ä»“åº“2ï¼ˆå­¦é•¿çš„ä»£ç ï¼‰**: `https://github.com/SaeProx/R-INN-RecentWork`

---

## 1. åº•å±‚å®ç°å·®å¼‚

### 1.1 ActNormå±‚

#### ä½ ä»¬çš„å®ç° (`actnorm/actnorm.py`)
```python
class ActNorm(torch.jit.ScriptModule):  # ç»§æ‰¿è‡ªScriptModule
    def __init__(self, num_features: int):
        super().__init__()
        self.scale = torch.nn.Parameter(torch.zeros(num_features))
        self.bias = torch.nn.Parameter(torch.zeros(num_features))
        self.register_buffer("_initialized", torch.tensor(False))
```

**å…³é”®ç‰¹ç‚¹**:
- ç»§æ‰¿è‡ª `torch.jit.ScriptModule`ï¼Œæ”¯æŒTorchScriptç¼–è¯‘
- æ”¯æŒæ•°æ®ä¾èµ–åˆå§‹åŒ–ï¼ˆé¦–æ¬¡forwardæ—¶æ ¹æ®æ•°æ®ç»Ÿè®¡åˆå§‹åŒ–scaleå’Œbiasï¼‰
- å®ç°äº†å®Œæ•´çš„forward/inverse/log_det_jacobian
- æ”¯æŒ1D/2D/3Dæ•°æ®ï¼ˆActNorm1d/2d/3dï¼‰
- åŒ…å«ç»´åº¦æ£€æŸ¥å’Œé”™è¯¯å¤„ç†

#### å­¦é•¿çš„å®ç° (`layers/actnorm.py`)
```python
class ActNorm(nn.Module):  # ç»§æ‰¿è‡ªæ ‡å‡†nn.Module
    def __init__(self, num_features: int) -> None:
        super().__init__()
        self.num_features = num_features
        self.scale = nn.Parameter(torch.zeros(num_features))
        self.bias = nn.Parameter(torch.zeros(num_features))
        self.register_buffer("_initialized", torch.tensor(False))
```

**å…³é”®ç‰¹ç‚¹**:
- ç»§æ‰¿è‡ªæ ‡å‡† `nn.Module`
- åŒæ ·æ”¯æŒæ•°æ®ä¾èµ–åˆå§‹åŒ–
- å¢åŠ äº† `_validate_feature_dimension` æ–¹æ³•è¿›è¡Œç‰¹å¾ç»´åº¦éªŒè¯
- æ³¨é‡Šè¯´æ˜åŠ è½½å¤±è´¥æ—¶çš„fallbackå¤„ç†
- ä»£ç é£æ ¼æ›´è§„èŒƒï¼ˆç±»å‹æ³¨è§£ã€æ–‡æ¡£å­—ç¬¦ä¸²ï¼‰

**ä¸»è¦å·®å¼‚**:
| ç‰¹æ€§ | ä½ ä»¬çš„å®ç° | å­¦é•¿çš„å®ç° |
|------|-----------|-----------|
| åŸºç±» | `torch.jit.ScriptModule` | `nn.Module` |
| TorchScriptæ”¯æŒ | æ˜¯ | å¦ |
| ç‰¹å¾ç»´åº¦éªŒè¯ | åŸºç¡€æ£€æŸ¥ | è¯¦ç»†éªŒè¯æ–¹æ³• |
| åŠ è½½å®¹é”™ | æ ‡å‡†å¤„ç† | fallbackå¤„ç†inverse |

**æ€§èƒ½å½±å“**: TorchScriptç¼–è¯‘å¯èƒ½å¸¦æ¥è½»å¾®æ€§èƒ½æå‡ï¼Œä½†å­¦é•¿ç‰ˆæœ¬æ›´ç¨³å®šã€‚

---

### 1.2 JLLayerå±‚

#### ä½ ä»¬çš„å®ç° (`JL/jl.py`)
```python
class JLLayer(nn.Module):
    def __init__(self, dim: int, orthogonal_init: bool = True, use_weight_norm: bool = False):
        super().__init__()
        self.dim = dim
        self.linear = nn.Linear(dim, dim, bias=True)
        if orthogonal_init:
            nn.init.orthogonal_(self.linear.weight)
        else:
            nn.init.xavier_uniform_(self.linear.weight)
        
        if use_weight_norm:
            self.linear = parametrizations.weight_norm(self.linear, name='weight', dim=0)
        
        nn.init.zeros_(self.linear.bias)
    
    def log_det_jacobian(self, x: torch.Tensor) -> torch.Tensor:
        W = self.linear.weight
        sign, logabsdet = torch.slogdet(W)
        if torch.any(sign == 0):
            logabsdet = torch.where(sign == 0, torch.full_like(logabsdet, -1e6), logabsdet)
        return logabsdet.expand(x.shape[0])
```

**å…³é”®ç‰¹ç‚¹**:
- ä½¿ç”¨ `torch.slogdet` è®¡ç®—å¯¹æ•°è¡Œåˆ—å¼
- å¤„ç†å¥‡å¼‚çŸ©é˜µï¼ˆdet=0ï¼‰çš„æƒ…å†µ
- æ”¯æŒæ­£äº¤åˆå§‹åŒ–å’Œæƒé‡å½’ä¸€åŒ–
- ç®€å•ç›´æ¥çš„å®ç°

#### å­¦é•¿çš„å®ç° (`layers/jl.py`)
```python
class JLLayer(nn.Module):
    def __init__(self, dim: int, orthogonal_init: bool = True, use_weight_norm: bool = False):
        # ... ç›¸åŒåˆå§‹åŒ– ...
    
    def get_ortho_loss(self) -> torch.Tensor:
        """è®¡ç®—æ­£äº¤æ­£åˆ™åŒ–æŸå¤±: ||W^T @ W - I||^2"""
        W = self.linear.weight
        rows, cols = W.shape
        WtW = torch.matmul(W.t(), W)
        I = torch.eye(rows, device=W.device)
        loss = torch.sum((WtW - I) ** 2)
        return loss
    
    def log_det_jacobian(self, x: torch.Tensor) -> torch.Tensor:
        # ä¸ä½ ä»¬å®ç°ç›¸åŒ
```

**å…³é”®ç‰¹ç‚¹**:
- é¢å¤–å®ç°äº† `get_ortho_loss()` æ–¹æ³•
- æ­£äº¤æ­£åˆ™åŒ–æŸå¤±é¼“åŠ±æƒé‡çŸ©é˜µä¿æŒæ­£äº¤æ€§
- è¿™åœ¨ç†è®ºä¸Šç¡®ä¿äº†JLå±‚çš„å¯é€†æ€§

**ä¸»è¦å·®å¼‚**:
| ç‰¹æ€§ | ä½ ä»¬çš„å®ç° | å­¦é•¿çš„å®ç° |
|------|-----------|-----------|
| æ­£äº¤æ­£åˆ™åŒ– | æ—  | æœ‰ (get_ortho_loss) |
| ç†è®ºä¿è¯ | ä¾èµ–åˆå§‹åŒ– | è®­ç»ƒæ—¶å¼ºåˆ¶çº¦æŸ |
| è®­ç»ƒç¨³å®šæ€§ | å¯èƒ½é™ä½ | æ›´é«˜ |

**æ€§èƒ½å½±å“**: å­¦é•¿ç‰ˆæœ¬é€šè¿‡æ­£äº¤æŸå¤±è®­ç»ƒæ—¶æ›´ç¨³å®šï¼Œå¯é€†æ€§æ›´å¥½ã€‚

---

### 1.3 RealNVPå±‚

#### ä½ ä»¬çš„å®ç° (`realnvp/realnvp.py`)

**å…³é”®ç»„ä»¶**:

1. **ResBlock** (æ®‹å·®å—):
```python
class ResBlock(nn.Module):
    def __init__(self, hidden_dim):
        self.fc1 = nn.utils.weight_norm(nn.Linear(hidden_dim, hidden_dim))
        self.fc2 = nn.utils.weight_norm(nn.Linear(hidden_dim, hidden_dim))
        self.relu = nn.ReLU()
```

2. **AffineCoupling**:
```python
class AffineCoupling(nn.Module):
    def __init__(self, input_dim, x1_dim, hidden_dim):
        # scale_netä½¿ç”¨Tanh+weight_norm
        self.scale_net = nn.Sequential(
            nn.Linear(self.x1_dim, hidden_dim),
            nn.ReLU(),
            ResBlock(hidden_dim),
            nn.Linear(hidden_dim, self.x2_dim),
            nn.Tanh(),
            nn.utils.weight_norm(nn.Linear(self.x2_dim, self.x2_dim, bias=False))
        )
```

3. **FlowStage** (å…³é”®å·®å¼‚):
```python
class FlowStage(nn.Module):
    def __init__(self, input_dim, z_part_dim, h_prime_dim, x1_dim, hidden_dim, num_cycles=2):
        # å…ˆå¯¹æ•´ä¸ªè¾“å…¥æ‰§è¡Œcyclesï¼Œå†æ‹†åˆ†
        self.cells = nn.ModuleList([
            FlowCell(self.input_dim, x1_dim, hidden_dim) for _ in range(num_cycles)
        ])
    
    def forward(self, x):
        # å…ˆå¾ªç¯å†æ‹†åˆ†
        for cell in self.cells:
            x, log_det = cell(x)
        z_part = x[:, :self.z_part_dim]
        h_prime = x[:, self.z_part_dim:]
        return z_part, h_prime, log_det_total
```

4. **RealNVPä¸»ç±»** (é‡å¤§å·®å¼‚):
```python
class RealNVP(nn.Module):
    def __init__(self, ...):
        # é¢å¤–ç»„ä»¶
        self.fusion_mlps = nn.ModuleList()  # ç”¨äºèåˆz_partå’Œh_prime
        self.gaussian_priors = nn.ModuleList()  # é«˜æ–¯å…ˆéªŒåˆ†å¸ƒ
        self.final_gaussian_prior = GaussianPrior(...)
    
    def forward(self, x):
        for i in range(self.num_stages):
            z_part, h_prime, log_det = stage(current_h)
            
            # ä»¿å°„å˜æ¢èåˆï¼ˆä½ ä»¬ç‰¹æœ‰ï¼‰
            scale_shift = self.fusion_mlps[i](z_part)
            scale = scale_shift[:, :h_prime.shape[1]] * 0.5
            shift = scale_shift[:, h_prime.shape[1]:]
            current_h = h_prime * torch.exp(scale) + shift
            
            # é«˜æ–¯å…ˆéªŒè®¡ç®—ï¼ˆä½ ä»¬ç‰¹æœ‰ï¼‰
            log_pz = self.gaussian_priors[i].log_prob(z_part)
            total_log_pz += log_pz
```

#### å­¦é•¿çš„å®ç° (`layers/realnvp.py`)

1. **AffineCoupling**:
```python
class AffineCoupling(nn.Module):
    def __init__(self, input_dim, x1_dim, hidden_dim):
        # æ›´ç®€å•çš„ç»“æ„ï¼Œæ— ResBlock
        self.scale_net = nn.Sequential(
            nn.Linear(self.x1_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),  # æ— ResBlock
            nn.ReLU(),
            nn.Linear(hidden_dim, self.x2_dim),
            nn.Tanh()
        )
```

2. **FlowStage**:
```python
class FlowStage(nn.Module):
    def __init__(self, ...):
        # å…³é”®å·®å¼‚ï¼šå…ˆæ‹†åˆ†ï¼Œå†å¯¹h_primeæ‰§è¡Œcycles
        self.cells = nn.ModuleList([
            FlowCell(self.h_prime_dim, x1_dim, hidden_dim)  # æ³¨æ„æ˜¯h_prime_dim
            for _ in range(num_cycles)
        ])
    
    def forward(self, x):
        # å…ˆæ‹†åˆ†å†å¾ªç¯
        z_part, h_prime = self._split_input(x)
        h_prime, log_det_total = self._apply_internal_cycles(h_prime)
        return z_part, h_prime, log_det_total
```

3. **RealNVP**:
```python
class RealNVP(nn.Module):
    def __init__(self, ...):
        # æ›´ç®€æ´ï¼Œæ— fusion_mlpså’Œgaussian_priors
        self.stages = nn.ModuleList()
    
    def forward(self, x):
        for i in range(self.num_stages):
            z_part, current_h, log_det = stage(current_h)
            z_list.append(z_part)
        # æ— é¢å¤–èåˆæ“ä½œ
```

**ä¸»è¦å·®å¼‚æ€»ç»“**:

| ç‰¹æ€§ | ä½ ä»¬çš„å®ç° | å­¦é•¿çš„å®ç° | å½±å“ |
|------|-----------|-----------|------|
| AffineCoupling MLP | ä½¿ç”¨ResBlock | ä½¿ç”¨ä¸¤å±‚Linear+ReLU | ä½ ä»¬æ¨¡å‹å®¹é‡æ›´å¤§ |
| FlowStageé¡ºåº | å…ˆå¾ªç¯å†æ‹†åˆ† | å…ˆæ‹†åˆ†å†å¾ªç¯ | **é€»è¾‘ä¸åŒï¼Œå¯èƒ½å½±å“å¯é€†æ€§** |
| Fusion MLP | æœ‰ï¼ˆä½ ä»¬ç‰¹æœ‰ï¼‰ | æ—  | ä½ ä»¬æœ‰é¢å¤–å˜æ¢èƒ½åŠ› |
| Gaussian Prior | æœ‰ï¼ˆä½ ä»¬ç‰¹æœ‰ï¼‰ | æ—  | ä½ ä»¬æœ‰æ˜¾å¼å¯†åº¦å»ºæ¨¡ |
| é«˜æ–¯å¯å­¦ä¹ æ€§ | æ”¯æŒ | æ—  | ä½ ä»¬æ›´çµæ´» |

**âš ï¸ å…³é”®å‘ç°**: FlowStageçš„å¤„ç†é¡ºåºå®Œå…¨ç›¸åï¼
- **ä½ ä»¬**: å¯¹æ•´ä¸ªè¾“å…¥æ‰§è¡Œcycles â†’ æ‹†åˆ†
- **å­¦é•¿**: æ‹†åˆ† â†’ åªå¯¹h_primeæ‰§è¡Œcycles

è¿™å¯èƒ½å½±å“æ¨¡å‹çš„å¯é€†æ€§å’Œæ€§èƒ½ã€‚

---

## 2. æ¨¡å‹æ¶æ„å·®å¼‚

### 2.1 RINNBlock

#### ä½ ä»¬çš„å®ç° (`R_INN_model/rinn_model.py`)
```python
class RINNBlock(nn.Module):
    def __init__(self, input_dim, hidden_dim=10, num_stages=4, ...):
        self.actnorm = ActNorm1d(num_features=input_dim)
        self.realnvp = RealNVP(input_dim=input_dim, ...)
        self.jl_layer = JLLayer(dim=input_dim, orthogonal_init=True, use_weight_norm=False)
    
    def forward(self, x):
        x = self.actnorm(x)
        z_from_realnvp, log_det_realnvp, _ = self.realnvp(x)
        z = self.jl_layer(z_from_realnvp)
        log_det_jl = self.jl_layer.log_det_jacobian(z)
        log_det_actnorm = self.actnorm.log_det_jacobian(x)
        log_det_total = log_det_realnvp + log_det_jl + log_det_actnorm
        return z, log_det_total
```

**ç‰¹ç‚¹**:
- RealNVPè¿”å›3ä¸ªå€¼ï¼ˆä½ ä»¬çš„å®ç°ï¼‰
- åŒ…å« `forward_with_intermediate` æ–¹æ³•ç”¨äºè·å–ä¸­é—´ç»“æœ
- æ— æ­£äº¤æŸå¤±è®¡ç®—

#### å­¦é•¿çš„å®ç° (`arch.py`)
```python
class RINNBlock(nn.Module):
    def forward(self, x):
        x = self.actnorm(x)
        z, log_det_realnvp = self.realnvp(x)  # æ³¨æ„ï¼šåªè¿”å›2ä¸ªå€¼
        z = self.jl_layer(z)
        log_det_jl = self.jl_layer.log_det_jacobian(z)
        log_det_actnorm = self.actnorm.log_det_jacobian(x)
        log_det_total = log_det_realnvp + log_det_jl + log_det_actnorm
        ortho_loss = self.jl_layer.get_ortho_loss()  # æ­£äº¤æŸå¤±
        return z, log_det_total, ortho_loss
```

**ç‰¹ç‚¹**:
- RealNVPè¿”å›2ä¸ªå€¼ï¼ˆå­¦é•¿çš„å®ç°ï¼‰
- è¿”å› `ortho_loss` ç”¨äºè®­ç»ƒ
- æ—  `forward_with_intermediate`

### 2.2 RINNModel

#### ä½ ä»¬çš„å®ç°
```python
class RINNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim=64, num_blocks=3, ...):
        components = []
        for i in range(num_blocks):
            components.append(RINNBlock(...))
            # Shuffleå±‚è¢«æ³¨é‡Šæ‰
            # if i < num_blocks - 1:
            #     components.append(Shuffle(input_dim=input_dim))
        
        self.feature_adjustment = FinalFeatureAdjustment(input_dim=input_dim)
```

**é¢å¤–ç»„ä»¶**:
- `FinalFeatureAdjustment` å±‚ï¼ˆä½ ä»¬ç‰¹æœ‰ï¼‰
- Shuffleå±‚è¢«æ³¨é‡Šæ‰

#### å­¦é•¿çš„å®ç°
```python
class RINNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim=64, num_blocks=3, ...):
        self.blocks = nn.ModuleList([
            RINNBlock(...) for _ in range(num_blocks)
        ])
    
    def forward(self, x):
        for block in self.blocks:
            z, log_det, ortho_loss = block(z)
            log_det_total += log_det
            ortho_loss_total += ortho_loss
        return z, log_det_total, ortho_loss_total
```

**å·®å¼‚**:
- å­¦é•¿ç‰ˆæœ¬ä½¿ç”¨ `self.blocks` å‘½å
- å­¦é•¿ç‰ˆæœ¬ç´¯åŠ  `ortho_loss_total`
- ä½ ä»¬ç‰ˆæœ¬æœ‰é¢å¤–çš„ `feature_adjustment` å±‚

### 2.3 é…ç½®å‚æ•°

| å‚æ•° | ä½ ä»¬çš„é»˜è®¤å€¼ | å­¦é•¿çš„é»˜è®¤å€¼ |
|------|-------------|-------------|
| hidden_dim | 56 (è´å¶æ–¯ä¼˜åŒ–å) | 64 / 128 |
| num_blocks | 4 | 3 |
| num_stages | 2 | 4 |
| num_cycles_per_stage | 2 | 2 |
| ratio_toZ_after_flowstage | 0.273 | 0.3 |
| ratio_x1_x2_inAffine | 0.421 | 0.25 |

---

## 3. æ•°æ®å¤„ç†å·®å¼‚

### 3.1 æ•°æ®æ ¼å¼

#### ä½ ä»¬çš„å®ç° (`trains11RINN.py`)
```python
# ä»CSVæ–‡ä»¶åŠ è½½
data_files = ['data/S Parameter Plot300.csv', 'data/S Parameter Plot200.csv', ...]

# å¤æ‚çš„æ•°æ®è§£æ
def extract_geometry_params(col_name):
    """ä»åˆ—åä¸­æå–å‡ ä½•å‚æ•°H1, H2, H3, H_C1, H_C2"""
    h1_match = re.search(r"H1='([\d.]+)mm'", col_name)
    # ...

def load_data_from_csv(data_path):
    # è¯»å–è¡¨å¤´è·å–å‡ ä½•å‚æ•°
    with open(data_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        header = next(reader)
    # æå–å®éƒ¨å’Œè™šéƒ¨ï¼Œè½¬ç½®ï¼Œåˆå¹¶...
```

**ç‰¹ç‚¹**:
- æ”¯æŒCSVæ ¼å¼
- è‡ªåŠ¨è§£æHFSSå¯¼å‡ºçš„å¤æ‚åˆ—å
- åˆå¹¶å¤šä¸ªCSVæ–‡ä»¶
- æ”¯æŒé²æ£’æ ‡å‡†åŒ–ï¼ˆRobust Scalingï¼‰

#### å­¦é•¿çš„å®ç° (`data_load.py`)
```python
class MicrowaveDataset:
    def __init__(self, x_path='dataset_500DOE_aid/dataset_x.npy', 
                 y_path='dataset_500DOE_aid/dataset_y.npy', test_split=0.2):
        # åŠ è½½NPYæ–‡ä»¶
        raw_x = np.load(x_path)
        raw_y = np.load(y_path)
        
        # è½¬ç½®å¦‚æœå¿…è¦
        if raw_x.shape[0] < raw_x.shape[1]:
            raw_x = raw_x.T
        
        # æ ‡å‡†æ ‡å‡†åŒ–
        self.x_mean = raw_x.mean(axis=0)
        self.x_std = raw_x.std(axis=0) + 1e-6
        x_norm = (raw_x - self.x_mean) / self.x_std
```

**ç‰¹ç‚¹**:
- ä½¿ç”¨NPYæ ¼å¼ï¼ˆNumPyäºŒè¿›åˆ¶ï¼‰
- æ›´ç®€å•çš„åŠ è½½é€»è¾‘
- æ ‡å‡†æ ‡å‡†åŒ–ï¼ˆStandard Scalingï¼‰
- é¢„åˆ†å‰²è®­ç»ƒ/æµ‹è¯•é›†

### 3.2 æ•°æ®æ ‡å‡†åŒ–

| ç‰¹æ€§ | ä½ ä»¬çš„å®ç° | å­¦é•¿çš„å®ç° |
|------|-----------|-----------|
| æ–¹æ³• | Robust Scalingï¼ˆå››åˆ†ä½æ•°ï¼‰ | Standard Scalingï¼ˆå‡å€¼/æ ‡å‡†å·®ï¼‰ |
| å¼‚å¸¸å€¼å¤„ç† | è£å‰ªåˆ°[Q1-3*IQR, Q3+3*IQR] | æ—  |
| Yæ•°æ®é¢„å¤„ç† | è£å‰ªåæ ‡å‡†åŒ– | ç›´æ¥æ ‡å‡†åŒ– |
| é²æ£’æ€§ | æ›´é«˜ | æ ‡å‡† |

---

## 4. è®­ç»ƒå’Œè¯„ä¼°æ–¹æ³•å·®å¼‚

### 4.1 æŸå¤±å‡½æ•°

#### ä½ ä»¬çš„å®ç° (`R_INN_model/loss_methods.py`)

1. **MMDæŸå¤±**:
```python
def mmd_loss(dist1, dist2, sigma=None, log_det_total=None, lambda_logdet=0.1):
    """æœ€å¤§å‡å€¼å·®å¼‚æŸå¤±"""
    # ä½¿ç”¨é«˜æ–¯æ ¸å‡½æ•°
    kernel = torch.exp(-dist_sq / (2 * sigma ** 2))
    # å¯é€‰åœ°çº³å…¥é›…å¯æ¯”è¡Œåˆ—å¼æ­£åˆ™åŒ–
```

2. **NMSEæŸå¤±**:
```python
def nmse_loss(y_real, y_pred, eps=1e-4):
    """å½’ä¸€åŒ–å‡æ–¹è¯¯å·®"""
    mse = torch.mean((y_real - y_pred) ** 2)
    real_rms = torch.sqrt(torch.mean(y_real ** 2) + eps)
    return mse / (real_rms ** 2 + eps)
```

3. **åŠ æƒNMSEæŸå¤±**:
```python
def weighted_nmse_loss(y_real, y_pred, weights=None, eps=1e-4):
    """å¸¦æƒé‡çš„NMSEï¼Œå¯¹è°·å€¼ç»™äºˆæ›´é«˜æƒé‡"""
    # è‡ªåŠ¨ç”ŸæˆåŸºäºyå€¼åˆ†å¸ƒçš„æƒé‡
    weights = torch.exp(2 * normalized_avg)
```

#### å­¦é•¿çš„å®ç° (`solver_final_robust.py`)

```python
def calculate_loss(model, x, y, w_x=50.0, w_y=50.0, w_z=0.0001, w_ortho=10.0):
    batch_size = x.shape[0]
    device = x.device
    model_dim = model.input_dim
    
    # å¡«å……Xåˆ°æ¨¡å‹ç»´åº¦
    x_padded = torch.zeros(batch_size, model_dim).to(device)
    real_x_dim = x.shape[1]
    x_padded[:, :real_x_dim] = x
    
    z, log_det_forward, ortho_loss = model(x_padded)
    x_recon_full, _ = model.inverse(z)
    x_recon = x_recon_full[:, :real_x_dim]
    
    # ç®€å•MSEæŸå¤±
    Ly = torch.mean((z - y) ** 2)
    Lx = torch.mean((x_recon - x) ** 2)
    L_jacobian = -torch.mean(log_det_forward)
    
    total_loss = (w_x * Lx) + (w_y * Ly) + (w_z * L_jacobian) + (w_ortho * ortho_loss)
    return total_loss
```

**ä¸»è¦å·®å¼‚**:

| æŸå¤±é¡¹ | ä½ ä»¬çš„å®ç° | å­¦é•¿çš„å®ç° |
|--------|-----------|-----------|
| Yé¢„æµ‹æŸå¤± | åŠ æƒNMSE | ç®€å•MSE |
| Xé‡å»ºæŸå¤± | MMD | ç®€å•MSE |
| Zåˆ†å¸ƒçº¦æŸ | MMD (ä¸æ ‡å‡†é«˜æ–¯) | é€šè¿‡Jacobiané¡¹ |
| æ­£äº¤æŸå¤± | æ—  | æœ‰ (w_ortho) |
| Jacobiané¡¹ | å¯é€‰çº³å…¥MMD | æ˜¾å¼è´Ÿå¯¹æ•°è¡Œåˆ—å¼ |

### 4.2 è®­ç»ƒå¾ªç¯

#### ä½ ä»¬çš„å®ç° (`trains11RINN.py`)
```python
# å¤æ‚çš„è®­ç»ƒé…ç½®
config = {
    "model_config": {...},
    "training_params": {
        "batch_size": 16,
        "gradient_accumulation_steps": 1,
        "learning_rate": 0.000659,
        "weight_decay": 1.5e-06,
        "clip_value": 0.5,
        "num_epochs": 150,
        "loss_weights": {
            "weight_y": 0.626,
            "weight_x": 0.233,
            "weight_z": 0.254
        }
    }
}

# å­¦ä¹ ç‡è°ƒåº¦
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10, threshold=1e-6
)

# æ—©åœæœºåˆ¶
patience = 60
if patience_counter >= patience:
    print(f'æ—©åœè§¦å‘! éªŒè¯æŸå¤±è¿ç»­{patience}ä¸ªepochæ²¡æœ‰æ”¹å–„')
    break

# è¯¦ç»†çš„éªŒè¯æŒ‡æ ‡è®¡ç®—
avg_val_nmse = total_val_nmse / len(val_loader)
backward_prediction_accuracy = 1.0 - avg_relative_error
```

#### å­¦é•¿çš„å®ç° (`solver_final_robust.py`)
```python
# ç®€å•é…ç½®
BATCH_SIZE = 32
NUM_EPOCHS = 3000
HIDDEN_DIM = 128
NUM_BLOCKS = 3
LR = 1e-3
WEIGHT_DECAY = 1e-4

# ç®€å•å­¦ä¹ ç‡è°ƒåº¦
scheduler = StepLR(optimizer, step_size=500, gamma=0.5)

# ç®€å•çš„éªŒè¯
if (epoch + 1) % 50 == 0:
    test_x, test_y = data_manager.get_test_data()
    x_recon_padded, _ = model.inverse(test_y)
    x_pred = x_recon_padded[:, :real_x_dim]
    curr_mse = torch.mean((x_pred - test_x) ** 2).item()
    
    if curr_mse < best_mse:
        best_mse = curr_mse
        torch.save(model, BEST_MODEL_PATH)  # ä¿å­˜æ•´ä¸ªæ¨¡å‹å¯¹è±¡
```

**ä¸»è¦å·®å¼‚**:

| ç‰¹æ€§ | ä½ ä»¬çš„å®ç° | å­¦é•¿çš„å®ç° |
|------|-----------|-----------|
| é…ç½®æ–¹å¼ | JSONé…ç½®æ–‡ä»¶ | ç¡¬ç¼–ç å¸¸é‡ |
| è®­ç»ƒè½®æ•° | 150 (æ—©åœ) | 3000 |
| å­¦ä¹ ç‡è°ƒåº¦ | ReduceLROnPlateau | StepLR |
| æ¢¯åº¦ç´¯ç§¯ | æ”¯æŒ | æ—  |
| ä¿å­˜ç­–ç•¥ | state_dict | æ•´ä¸ªæ¨¡å‹å¯¹è±¡ |
| éªŒè¯é¢‘ç‡ | æ¯epoch | æ¯50 epochs |

### 4.3 ä¼˜åŒ–å™¨

#### ä½ ä»¬çš„å®ç°
```python
optimizer = optim.AdamW(
    model.parameters(),
    lr=config['training_params']['learning_rate'],
    weight_decay=config['training_params']['weight_decay']
)
```

#### å­¦é•¿çš„å®ç°
```python
optimizer = optim.Adam(
    model.parameters(), 
    lr=LR, 
    weight_decay=WEIGHT_DECAY
)
```

**å·®å¼‚**: ä½ ä»¬ä½¿ç”¨AdamWï¼ˆæ›´å¥½çš„æƒé‡è¡°å‡ï¼‰ï¼Œå­¦é•¿ä½¿ç”¨Adamã€‚

---

## 5. è¶…å‚æ•°ä¼˜åŒ–

### ä½ ä»¬çš„å®ç° (`bayesian_optimization.py`)

**ä½¿ç”¨Optunaè¿›è¡Œè´å¶æ–¯ä¼˜åŒ–**:
```python
def objective(trial):
    params = {
        "hidden_dim": trial.suggest_int("hidden_dim", 32, 128, step=8),
        "num_blocks": trial.suggest_int("num_blocks", 3, 8),
        "num_stages": trial.suggest_int("num_stages", 1, 4),
        "ratio_toZ_after_flowstage": trial.suggest_float("ratio_toZ_after_flowstage", 0.1, 0.7),
        "learning_rate": trial.suggest_float("learning_rate", 1e-5, 1e-3, log=True),
        # ... æ›´å¤šå‚æ•°
    }
    # è®­ç»ƒå¹¶è¿”å›éªŒè¯æŸå¤±
```

**ç‰¹ç‚¹**:
- è‡ªåŠ¨åŒ–è¶…å‚æ•°æœç´¢
- æ”¯æŒ11ä¸ªè¶…å‚æ•°çš„è”åˆä¼˜åŒ–
- å¯è§†åŒ–å‚æ•°é‡è¦æ€§

### å­¦é•¿çš„å®ç°
- æ— è¶…å‚æ•°ä¼˜åŒ–è„šæœ¬
- ä½¿ç”¨ç»éªŒè®¾å®šçš„å›ºå®šå‚æ•°

---

## 6. æ¨ç†å’Œç”Ÿæˆ

### ä½ ä»¬çš„å®ç° (`generate_and_visualize_x.py`)

**åŠŸèƒ½**:
- ä»Yç”Ÿæˆå¤šä¸ªXå€™é€‰
- è¯¦ç»†çš„è¯¯å·®åˆ†æï¼ˆç»å¯¹è¯¯å·®ã€ç›¸å¯¹è¯¯å·®ï¼‰
- å¤šç§å¯è§†åŒ–ï¼ˆæŸ±çŠ¶å›¾ã€çƒ­åŠ›å›¾ã€é›·è¾¾å›¾ï¼‰
- è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„Xï¼ˆæ­£å‘é¢„æµ‹æ£€æŸ¥ï¼‰
- ä¿å­˜CSVå’ŒJSONæ ¼å¼ç»“æœ

### å­¦é•¿çš„å®ç° (`solver_inference_single.py`)

**åŠŸèƒ½**:
- å•æ ·æœ¬æ¨ç†
- NMSEè®¡ç®—
- Round-tripéªŒè¯
- ç®€å•çš„æ–‡æœ¬æŠ¥å‘Š

---

## 7. å…³é”®å‘ç°å’Œå»ºè®®

### 7.1 å¯èƒ½å½±å“æ€§èƒ½çš„å…³é”®å·®å¼‚

#### ğŸ”´ é«˜é£é™©å·®å¼‚

1. **FlowStageå¤„ç†é¡ºåºç›¸å**
   - **é—®é¢˜**: ä½ ä»¬å…ˆå¾ªç¯åæ‹†åˆ†ï¼Œå­¦é•¿å…ˆæ‹†åˆ†åå¾ªç¯
   - **å½±å“**: å¯èƒ½å¯¼è‡´å¯é€†æ€§é—®é¢˜å’Œæ€§èƒ½å·®å¼‚
   - **å»ºè®®**: å®éªŒéªŒè¯å“ªç§é¡ºåºæ›´å¥½ï¼Œæˆ–æ£€æŸ¥è®ºæ–‡åŸæ–‡

2. **é¢å¤–çš„Fusion MLPå’ŒGaussian Prior**
   - **é—®é¢˜**: ä½ ä»¬çš„å®ç°æœ‰é¢å¤–çš„å˜æ¢å±‚
   - **å½±å“**: å¢åŠ æ¨¡å‹å¤æ‚åº¦ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆ
   - **å»ºè®®**: å¯¹æ¯”å®éªŒï¼Œè¯„ä¼°æ˜¯å¦æœ‰å¿…è¦

#### ğŸŸ¡ ä¸­ç­‰é£é™©å·®å¼‚

3. **æ­£äº¤æŸå¤±ç¼ºå¤±**
   - **é—®é¢˜**: ä½ ä»¬çš„ä»£ç æ²¡æœ‰ `get_ortho_loss`
   - **å½±å“**: JLå±‚å¯èƒ½åç¦»æ­£äº¤æ€§ï¼Œå½±å“å¯é€†æ€§
   - **å»ºè®®**: æ·»åŠ æ­£äº¤æŸå¤±ï¼Œæƒé‡å‚è€ƒå­¦é•¿ä»£ç (w_ortho=10.0)

4. **æŸå¤±å‡½æ•°å¤æ‚åº¦**
   - **é—®é¢˜**: ä½ ä»¬ä½¿ç”¨å¤æ‚çš„MMD+åŠ æƒNMSEç»„åˆ
   - **å½±å“**: è®­ç»ƒæ›´å¤æ‚ï¼Œå¯èƒ½éš¾ä»¥æ”¶æ•›
   - **å»ºè®®**: å°è¯•å­¦é•¿çš„ç®€å•MSEæ–¹æ¡ˆä½œä¸ºåŸºå‡†

#### ğŸŸ¢ ä½é£é™©å·®å¼‚

5. **æ•°æ®æ ¼å¼**
   - CSV vs NPYåªæ˜¯æ ¼å¼å·®å¼‚
   - ä½ ä»¬çš„é²æ£’æ ‡å‡†åŒ–å¯èƒ½æ›´ç¨³å®š

6. **è®­ç»ƒè½®æ•°**
   - å­¦é•¿è®­ç»ƒ3000è½®ï¼Œä½ ä»¬ä½¿ç”¨æ—©åœ
   - éœ€è¦å¯¹æ¯”æ”¶æ•›æ›²çº¿

### 7.2 å»ºè®®çš„ä¼˜åŒ–æ–¹å‘

1. **ç»Ÿä¸€FlowStageé€»è¾‘**
   ```python
   # å»ºè®®éªŒè¯ä¸¤ç§é¡ºåºçš„æ€§èƒ½å·®å¼‚
   # ä½ ä»¬çš„ç‰ˆæœ¬ï¼šå…ˆå¾ªç¯å†æ‹†åˆ†
   # å­¦é•¿çš„ç‰ˆæœ¬ï¼šå…ˆæ‹†åˆ†å†å¾ªç¯
   ```

2. **æ·»åŠ æ­£äº¤æŸå¤±**
   ```python
   # åœ¨ä½ ä»¬çš„RINNBlock.forwardä¸­æ·»åŠ 
   ortho_loss = self.jl_layer.get_ortho_loss()
   return z, log_det_total, ortho_loss
   
   # åœ¨è®­ç»ƒä¸­æ·»åŠ æƒé‡
   total_loss += w_ortho * ortho_loss
   ```

3. **ç®€åŒ–æŸå¤±å‡½æ•°å®éªŒ**
   ```python
   # å°è¯•å­¦é•¿çš„ç®€å•æŸå¤±ä½œä¸ºåŸºå‡†
   total_loss = (w_x * Lx) + (w_y * Ly) + (w_z * L_jacobian)
   ```

4. **è¶…å‚æ•°å¯¹é½**
   - ä½¿ç”¨å­¦é•¿çš„é…ç½®ä½œä¸ºèµ·ç‚¹ï¼š
     - hidden_dim=128
     - num_blocks=3
     - num_stages=4
     - ratio_toZ=0.3
     - ratio_x1=0.25

5. **ActNormåŸºç±»**
   - è€ƒè™‘ç§»é™¤ `torch.jit.ScriptModule` ä¾èµ–
   - ä½¿ç”¨æ ‡å‡† `nn.Module` æé«˜ç¨³å®šæ€§

### 7.3 æ€§èƒ½å¯¹æ¯”å®éªŒå»ºè®®

åˆ›å»ºæ¶ˆèå®éªŒå¯¹æ¯”ä»¥ä¸‹é…ç½®ï¼š

| å®éªŒ | FlowStageé¡ºåº | Fusion MLP | Gaussian Prior | æ­£äº¤æŸå¤± | æŸå¤±å‡½æ•° |
|------|--------------|------------|----------------|----------|----------|
| åŸºå‡†(å­¦é•¿) | å…ˆæ‹†åˆ† | æ—  | æ—  | æœ‰ | ç®€å•MSE |
| å½“å‰(ä½ ä»¬) | å…ˆå¾ªç¯ | æœ‰ | æœ‰ | æ—  | MMD+NMSE |
| æ··åˆ1 | å…ˆæ‹†åˆ† | æ—  | æ—  | æœ‰ | MMD+NMSE |
| æ··åˆ2 | å…ˆå¾ªç¯ | æœ‰ | æœ‰ | æœ‰ | MMD+NMSE |
| æ··åˆ3 | å…ˆæ‹†åˆ† | æ—  | æ—  | æœ‰ | ç®€å•MSE |

---

## 8. ä»£ç è´¨é‡å¯¹æ¯”

### ä½ ä»¬çš„ä¼˜åŠ¿
1. âœ… æ›´è¯¦ç»†çš„æ–‡æ¡£å’Œæ³¨é‡Š
2. âœ… æ›´å¤šçš„å¯è§†åŒ–åŠŸèƒ½
3. âœ… è¶…å‚æ•°ä¼˜åŒ–æ”¯æŒ
4. âœ… é²æ£’çš„æ•°æ®å¤„ç†
5. âœ… æ›´å®Œå–„çš„éªŒè¯æŒ‡æ ‡

### å­¦é•¿çš„ä¼˜åŠ¿
1. âœ… æ›´ç®€æ´çš„ä»£ç ç»“æ„
2. âœ… æ›´å¥½çš„ä»£ç è§„èŒƒï¼ˆç±»å‹æ³¨è§£ï¼‰
3. âœ… æ­£äº¤æŸå¤±ç¡®ä¿å¯é€†æ€§
4. âœ… æ›´ç¨³å®šçš„æ¨¡å‹ä¿å­˜ç­–ç•¥ï¼ˆå®Œæ•´å¯¹è±¡ï¼‰
5. âœ… æ›´ç®€å•çš„è®­ç»ƒæµç¨‹ï¼ˆæ˜“äºå¤ç°ï¼‰

---

## 9. æ€»ç»“

ä¸¤ä¸ªå®ç°çš„æ ¸å¿ƒå·®å¼‚åœ¨äºï¼š

1. **æ¶æ„ç»†èŠ‚**: FlowStageå¤„ç†é¡ºåºã€é¢å¤–çš„Fusionå±‚
2. **è®­ç»ƒç­–ç•¥**: æŸå¤±å‡½æ•°å¤æ‚åº¦ã€æ­£åˆ™åŒ–æ–¹æ³•
3. **ä»£ç é£æ ¼**: åŠŸèƒ½ä¸°å¯Œåº¦ vs ç®€æ´ç¨³å®šæ€§

**å»ºè®®çš„ä¸‹ä¸€æ­¥**:
1. é¦–å…ˆéªŒè¯FlowStageé¡ºåºçš„å½±å“
2. æ·»åŠ æ­£äº¤æŸå¤±
3. ä½¿ç”¨å­¦é•¿é…ç½®ä½œä¸ºèµ·ç‚¹è¿›è¡Œå®éªŒ
4. é€æ­¥å¼•å…¥ä½ ä»¬çš„æ”¹è¿›ï¼ˆé²æ£’æ ‡å‡†åŒ–ã€è¶…å‚æ•°ä¼˜åŒ–ï¼‰

---

*æŠ¥å‘Šç”Ÿæˆå®Œæˆ*
